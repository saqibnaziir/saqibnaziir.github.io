---
layout: archive
title: "Work Experience"
permalink: /work/
author_profile: true
classes: wide
gallery1:
  - url: /images/projects/vigo1.png
    image_path: /images/projects/vigo1.png
    alt: "iDFD"
    title: "iDFD"
  - url: /images/projects/vigo2.png
    image_path: /images/projects/vigo2.png
    alt: "iDFD-samples"
    title: "iDFD-samples"
gallery2:
  - url: /images/projects/citius1.PNG
    image_path: /images/projects/thumbs/citius1.PNG
    alt: "Menelaos Summer School @ CiTIUS"
    title: "Menelaos Summer School @ CiTIUS"
  - url: /images/projects/citius2.png
    image_path: /images/projects/thumbs/citius2.png
    alt: "2HDED:NET"
    title: "2HDED:NET"
  - url: /images/projects/citius3.png
    image_path: /images/projects/thumbs/citius3.png
    alt: "MENELAOS"
    title: "MENELAOS"
gallery3:
  - url: /images/projects/massiccc-1.jpg
    image_path: /images/projects/thumbs/massiccc-1.jpg
    alt: "MASSICCC web app screenshot"
    title: "MASSICCC web app"
  - url: /images/projects/massiccc-2.jpg
    image_path: /images/projects/thumbs/massiccc-2.jpg
    alt: "MASSICCC web app screenshot"
    title: "MASSICCC web app"
  - url: /images/projects/massiccc-3.jpg
    image_path: /images/projects/thumbs/massiccc-3.jpg
    alt: "MASSICCC web app screenshot"
    title: "MASSICCC web app"
gallery4:
  - url: /images/projects/SRGAN.png
    image_path: /images/projects/SRGAN.png
    alt: "SRGAN"
    title: "SRGAN"
gallery6:
  - url: /images/projects/COSURIA.png
    image_path: /images/projects/COSURIA.png
    alt: "COSURIA"
    title: "COSURIA"  
---
**PostDoc Research Associate**, *GREYC LAB* <span class="pull-right">2024 </span>  
<span class="small-grey"><i class="fas fa-tools" aria-hidden="true"></i> 3D, Deep Learning</span>
Research Associate at [COSURIA](https://lezoray.users.greyc.fr/projects/COSURIA/index.html) project. The COSURIA project is an emerging project of the Normandy Research system funded from November 2023 to November 2025. In the COSURIA project, we propose to design methods based on generative neural networks to perform geometry and color completion on colored 3D meshes of people scans.
The developed algorithms will be used in the consolidation of 3D scans of people in order to create 3D avatars for extended reality.
With the development of 3D acquisition techniques, 3D data in the form of 3D surfaces have become very widely available and new application fields have emerged: digital forensics, digital heritage, and digital twins. But there are many obstacles. In fact, whatever the 3D acquisition process:


<i class="fas fa-plus small-grey"></i> The data is imperfect: gaps, acquisition errors, elements to be deleted.  <br>
<i class="fas fa-plus small-grey"></i> Retouching these 3D surfaces takes a very long time.  <br>
<i class="fas fa-plus small-grey"></i> Existing completion techniques only deal with geometry and not colors. <br>
<i class="fas fa-plus small-grey"></i> The goal of the project is to develop methods for completing both geometry and color in 3D color meshes. <br>
{% include gallery id="gallery6" caption="3D Human Face Mesh" %}



**Assistant Reseracher**, *CEOSpace Tech* <span class="pull-right">2021 - 2023</span>  
<span class="small-grey"><i class="fas fa-tools" aria-hidden="true"></i> AI, Deep Learning, Machine Vision, Python</span>  
Assistant Researcher for [European Training Network (ETN) MENELAOS](https://www.menelaos-nt.eu/) mission. Acquiring the 3D geometry of the scene is essential for many applications in the areas of navigation, robotics, scene understanding, etc. Among the existing approaches, those using passive devices are of increased interest since they allow the use of compact, standard, and low-cost imaging systems like DSLR cameras. There are many depth cues that can be used to extract the 3D geometry. In single-shot images, the depth is lying in the blur, shadows of objects, chromatic effects shape distortions caused by lens aberrations, etc.  When multiple images are used, depth information comes from perspective change like in binocular systems or structures motion in video sequences. The physics of these effects is well known and more or less accurate mathematical models exist and are used by analytical image processing methods that are generally prone to heavy calculation.
The entrance of the new Deep Neural Networks (DNN) on the stage of signal processing has boosted the subject due to their capability to learn complex models that ingest multiple effects, not only single ones as analytical approaches are doing. The flexibility in learning and the fast processing, once the training is accomplished, make DNNs a very promising tool in building the 3D geometry of scenes from easy-to-acquire images.


<i class="fas fa-plus small-grey"></i> Study of physical foundation for depth cues in images and evaluation of their potential in existing methods for depth mapping.  <br>
<i class="fas fa-plus small-grey"></i> Elaboration of DNN-based solutions for depth inference from single-shot images by exploiting defocus and other depth cues.  <br>
<i class="fas fa-plus small-grey"></i> Definition of benchmarks for DNN training, validation and testing. <br>
<i class="fas fa-plus small-grey"></i> Evaluation of the accuracy of depth maps obtained with the DNNs using indoor and outdoor image collection.<br>


**Visiting Researcher**, *Ingeniería INSITU (INSITU Engineering)* <span class="pull-right">2022 - 2022</span>  
<span class="small-grey"><i class="fas fa-tools" aria-hidden="true"></i>  AI, Deep Learning, Machine Vision, Python</span>  
Research engineer, within the Ingeniería INSITU (INSITU Engineering) team. The aim of this research stay at the University of Vigo was to explore the LiDAR and TOF cameras and develop a real dataset for Depth from Defocus. The iDFD is an open-source dataset that can be used for 3D indoor applications. [iDFD](https://github.com/saqibnaziir/iDFD)

<i class="fas fa-plus small-grey"></i> Contribution to open-source projects for the team.   <br>
<i class="fas fa-plus small-grey"></i> Devlopment of iDFD dataset. <br>
<i class="fas fa-plus small-grey"></i> Public presentation of the project, as well as contributing to research papers.<br>

<span class="small-grey"><i class="fab fa-fw fa-github" aria-hidden="true"></i>[Source code](https://github.com/saqibnaziir/iDFD)</span>
<span class="small-grey"><i class="fab fa-fw fa-chrome" aria-hidden="true"></i>[Web app](https://github.com/saqibnaziir/iDFD)</span>
{% include gallery id="gallery1" caption="iDFD dataset" %}


**Visiting Researcher**, *CiTiUS (Centro Singular de Investigación en Tecnoloxías Intelixentes)* <span class="pull-right">2021 - 2021</span>  
<span class="small-grey"><i class="fas fa-tools" aria-hidden="true"></i>  AI, Deep Learning, Machine Vision, Python</span>  
Research engineer within the CiTIUS, working on [European Training Network (ETN) MENELAOS](https://www.menelaos-nt.eu/) project. This collaboration was done between the CiTIUS team for the development of 2HDED:NET. 

<i class="fas fa-plus small-grey"></i> Development of 2HDED:NET. <br>
<i class="fas fa-plus small-grey"></i> Training and testing of 2HDED:NET on NYU-Depth v2 and Make3D datasets for DFD and Image deblurring. <br>
<i class="fas fa-plus small-grey"></i> Public presentation of the project, as well as contributing to research papers. <br>

<span class="small-grey"><i class="fab fa-fw fa-github" aria-hidden="true"></i>[Source code](https://ieeexplore.ieee.org/document/9897352)</span>
<span class="small-grey"><i class="fab fa-fw fa-chrome" aria-hidden="true"></i>[Web app](https://ieeexplore.ieee.org/document/9897352)</span>
{% include gallery id="gallery2" caption="2HDED:NET for Joint DFD and Image Deblurring" %}



**Machine learning internship**, *MIDL-NCAI-HEC COMSATS University, Islamabad (Pakistan)* <span class="pull-right">2017 - 2020</span>  
<span class="small-grey"><i class="fas fa-tools" aria-hidden="true"></i>  AI, Deep Learning, Machine Vision, Python</span>  
For my Master's thesis, I worked on a project in collaboration with the Medical Imaging and Diagnostic Lab (MIDL) affiliated with the National
Center of Artificial Intelligence (NCAI) under the Higher Education Commission (HEC) of Pakistan.  <br>
<i class="fas fa-plus small-grey"></i> Aim to provide Computer Aided Diagnostics (CAD) system solutions using advanced Computer Vision and Deep Learning techniques
(e.g., Discriminative Models and Generative Models specifically Generative Adversarial Networks). <br>
<i class="fas fa-plus small-grey"></i> Master's research thesis "Generative Adversarial Networks for Enhancing LowDose CT scans". <br> 
<i class="fas fa-plus small-grey"></i> Research Interest: Artificial Intelligence, Machine Learning, Deep
Learning, Computer Vision, Generative Adversarial Networks. <br>

<span class="small-grey"><i class="fab fa-fw fa-github" aria-hidden="true"></i>[Source code](https://github.com/saqibnaziir/SRGAN-Low-dose-CT-Scan-Denoising)</span>

{% include gallery id="gallery4" caption="SRGAN fro Low-dose CT-Scan Denoising" %}

<script src="https://cdn.jsdelivr.net/npm/aos@2.3.1/dist/aos.js"></script>
<link href="https://cdn.jsdelivr.net/npm/aos@2.3.1/dist/aos.css" rel="stylesheet">
<script>
  AOS.init();
</script>

